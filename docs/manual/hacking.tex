\chapter{Hacking}

This chapter is all about making cool things with Mongrel2.  It covers all the non-deployment
features that you get from the browser side and the handler/backend side of your application.
I'll show you how the chat demo works for the async web sockets.  I'll get into writing your
own handlers using a few other demos.  I'll cover some of the interesting things you can
do with Mongrel2 you can't do with other servers.  Finally I'll get into practical things
when to do proxying and when to use a 0MQ handler.

For the majority of this chapter I'll be using Python, but the demos should translate to
the other languages that are implemented.  I'll periodically show how another language
does one of the demos so you can get the idea that Mongrel2 is \emph{language agnostic}.
In no way should you take me using Python in this chapter to mean you can't use something
else for your handlers.

Currently supported languages are:

\begin{description}
\item [Python] When you installed the \shell{m2sh} gear you also got a \ident{mongrel2} Python library.
\item [Ruby] Ruby support, and probably the most extensive supported language, with good Rack support, by \href{http://github.com/perplexes/m2r}{perplexes on github}.
\item [C++] C++ support by \href{http://github.com/akrennmair/mongrel2-cpp}{akrennmair on github}
\item [PHP] PHP support by \href{http://github.com/winks/m2php}{winks on github}.
\item [C] You can also write handlers in C using the Mongrel2 library, but is really rough, so not recommended yet.  A C library will come though.
\item [Others?] \href{http://zeromq.org}{ZeroMQ} supports Ada, Basic, C, C++, Common Lisp, Erlang, Go, Haskell, Java, Lua, .NET, Objective-C, ooc, Perl, PHP, Python, and Ruby so after reading this chapter you can easily write handlers in any of those languages too.
\end{description}

However, no matter how many languages Mongrel2 supports, you will still have applications that
can't fit into 0MQ handlers and just work better as classic web apps.  Either because you've
already written them and have existing infrastructure, or because of some architectural issues
that require it to run traditionally.  Because of that Mongrel2 supports \emph{HTTP proxying}
which allows you to route requests to basic web server backends that don't support 0MQ.

\begin{aside}{What About FastCGI/AJP/CGI/SCGI/WSGI/Rack?}
Nothing prevents you from writing your own connector between Mongrel2 and your 
deployment protocol of choice.  If you need to run FastCGI or AJP in your environment
then your best bet is to just make a handler that translates Mongrel2 requests
to the protocol you need and back.  The Mongrel2 format is very easy to parse and
translate so you should be able to do it no problem.  The Ruby library already supports
Rack as an example, and Python will support WSGI soon.

However, Mongrel2 itself doesn't support any of these directly.  Doing so would bring
back the language specific infections that cause other web servers to go south.  The 
design of most of these protocols tend to be either before the modern web, or specific
to one particular language.  Instead of trying to cater to all the possible languages
out there, Mongrel2 just gives the tools to connect to it yourself.
\end{aside}


\section{Front-end Goodies}

Mongrel2 supports your standard web server features like serving files, routing requests to 
another HTTP server, multiple host matching, good 304 support, and just generally being able
to interact with a browser like normal.  You've seen most of these features as you setup and
deployed a Mongrel2 configuration, but let's go through some of them in more detail so you
know what's possible.


\subsection{HTTP}

Mongrel2 uses the original Mongrel parser that powers quite a few other web servers and large
successful websites.  This parser is rock solid, dead accurate, and by design blocks a lot of
security attacks.  For the most part you don't have to worry about this and just need to know
Mongrel2 is using the same stable HTTP processing that has been working great for many years.

Another way to put this is if Mongrel2 says your request is invalid, it most definitely is.

\begin{aside}{Idiots And RFC Implementers}
I don't know why, but people who implement RFCs pick up very weird cargo cult
beliefs peddled by the people who write the standards.  In HTTP it was two things
which the creators of HTTP have actually pack-peddled on:  Accept everything, and 
keep-alives with pipe-lines.

The truth is, if you want a secure server of \emph{any} kind blindly accepting every 
single thing any idiots sends you is going to open your server up to a huge number
of attacks.  If you look at every attack on existing HTTP servers you'll find that 
about 80\% of them are exploiting ambiguous parts of the HTTP grammar to pass
through malicious content or overflow buffers.  In Mongrel2 we use a parser that rejects
invalid requests from first basic principles using technology that's 30 years old and
backed by solid mathematics.  Not only does MOngrel2 reject bad requests, but it can
tell you \emph{why} the request was bad, just like a compiler.  This doesn't mean
Mongrel2 is ruthless, but it definitely doesn't tolerate ambiguity or stupidity.

Mongrel2 completey supports keep-alives because now, since it's not using Ruby 
\emph{at all} it can scale up beyond 1024 file descriptors.  Ruby was limited
in the number of open files a process could have, so the original Mongrel had
to break keep-alive and kill connections in order to save itself from greedy
browsers that never close them.  Mongrel2 doesn't have this limitation so it
uses full keep-alives and has a dead accurate state machine to manage them correctly.

Where problems come in is with pipe-lined requests meaning a browser sends a bunch
of requests in a big blast, then hangs out for all the responses.  This was such a
horrible stupid idea that pretty much everone gets it wrong and doesn't support it
fully, if at all.  The reason is its much too easy to blast a server with a ton
of request, wait a bit so they hit proxied backends, and then close the socket.  The
web server and the backends are now screwed having to handle these requests which will
go nowhere.

Mongrel2 does \emph{not} support pipe-lined requests.  It sends one, and waits for the
reponse, and if you want more then tough.  Screw you because it has \emph{no} advantage
for Mongrel2 and dubious advantages to you.  It is simply one more attack vector for
the server and is rejected outright.

These two things are rejected outright by Mongrel2 simply because they are stupid ideas
and in 2010 nobody should be writing clients so badly that they need these features.
\end{aside}

\subsection{Proxying}

You've already seen configurations that have the Proxy routes working, so it should
be easy to understand what's going on.  You just create routes to backends that are
HTTP servers and Mongrel2 shuttles requests to them, then proxies responses back.

The Proxying support in Mongrel2 is accurate, but it's not very capable right now.  For
example there's not round-robin backend selection, or page caching, or other things you
might need for more serious deployments.  Those features will come eventually though.

What you do get with Mongrel2's proxying though is a dead accurate way of slicing up
your application by routes.  Other web servers make you go through great pain in order
to have some URLs go to a proxy and others go to handlers or directories.  They make you
use odd "file syntax", weird pseudo-turing logic if-statements, and other odd hacks
to get flexible route selection.  They also tend to not maintain keep-alives properly
between proxy requests and other requests.

Mongrel2 uses the exact same routing syntax for all backends and has no distinction between
them.  It also properly does keep-alives for as long as it is efficient to do so.


\subsection{WebSockets}

Mongrel2 supports WebSockets in that if someone connects with a WebSocket then it will get
sent to handlers that use 0MQ and they can interact with it like every other request.  WebSockets
are the least supported though since they aren't fully baked and nobody's bothered to write
helper gear for handlers.  They work in theory, but in practice haven't really been tried.

If you try them out and find things that need fixing let us know.

\begin{aside}{Death To WebSockets}
I am getting sick of these "Backroom RFCs" that are crafted around a bunch of huge
companies' crap implementations found in their existing products rather than things
real programmers need.  WebSockets is yet another example of this, with so many odd
features and annoying agendas that I hope it fails miserably.

First, it actually specifies \emph{unicode} for the wire protocol in the HTTP headers.
This is such a monumental bad idea and will break so many web servers and browsers that
I'm baffled how it got into the standard.  The only thing I can think of is some "reverse colonialist"
who thinks the world should a happy rainbow of Unicode demanded it be in there.  Unicode in
the wire protocol adds no linguistic value (nobody reads headers), complicates servers,
adds security concerns because Unicode is ambiguous, and also violates the existing HTTP standard
which specifies ASCII for the wire protocol.  As I've said before in this manual, writing
protocols is hard enough without having to translate and deal with weird UTF-8 Unicode bizarreness.

Second, there is an idiotic "encryption" mechanism for a key exchange that can only be
described as completely damaged and amateurish.  The scheme involves taking a regular 
number and then mixing in non-number characters, so \verb|1234| becomes \verb|1@%^2*(34| and then is
"decrypted" by just reading only the digits.  Yes, this encryption is so advanced you can do it
in your head visually.  I'm sorry but any obfuscation that can be done by an 11 year old on
paper is not encryption and should not be used at all.  Again, this smacks of some "clever" feature
one of the many corporations out there invented and not something any real programmer needs.

There's more, but these two alone are enough to decide to hold off on WebSockets until
they get their head straight and specify something that mere mortals can hope to implement.
\end{aside}

\subsection{JSSocket}

The Mongrel2 chat demo uses JSSocket to do its magic, and it works great, but it requires
Flash, and oh man do I absolutely hate flash.  However, it works, and works now, and works in every
browser, even really old busted ones.  That meant it's the first thing we implemented and 
the one we'll keep for a while until it proves itself not useful.  The chat demo we'll
cover will show you how to hook this up for fast async messaging and presence detection.


\subsection{Long Poll}

Mongrel2 just works as if everything is an HTTP long poll, it's just that normal request/responses
are super fast long polls.  For the most part you don't even need to know this exists, it's just
how things are and they make perfect sense.  You get requests from a certain server with a 
certain connected identity, and then you send stuff to that target.  That's it.  If you send it
one response, or a stream of them, or setup a long poll configuration, then that's up to you.


\subsection{Streaming}

Because everything that Mongrel2 is asynchronous, and it allows you to target any connected listeners
from your handlers, even with partial messages, you can easily do efficient streaming applications.  ZeroMQ
is an incredibly efficient transport mechanism, and with it you can send tons of information to many
browsers or clients at once.  This means streaming video and MP3 streams to listeners is very 
trivial.  We'll cover the mp3stream example where you get to see a simple implementation of the ICY
MP3 streaming protocol.

\subsection{N:M Responses}

What makes streaming, async messaging, and long poll designs so efficient in Mongrel2 is you can send 
\emph{one} message and target up to 128 with that one message.  This means sending large scale replies
to many browsers requires less copying of the message and less transports.

In addition to this, you can setup Mongrel2 with the help of some 0MQ to send
one request from a browser to as many target handlers as you like.  You can
even send them messages using \href{http://code.google.com/p/openpgm/}{OpenPGM}
for sending UDP messages reliably to clusters of computers.

This means that Mongrel2 is the only web server capable of sending one request
from a browser to N backends at once, and then return the replies from these
handlers to M browsers.  Not exactly sure what you could write with that but
it's probably something really damn cool.


\section{Introduction to ZeroMQ}


Learning to use \href{http://zeromq.org}{ZeroMQ} is a bit outside the scope of this book, but I'll give you
a quick introduction to it so that you can explore it further.  It is a very simple
system so hopefully you can figure it out from here.

What ZeroMQ ends up being is "sockets the way programmers think sockets work."  Programmers
usually hear about TCP or UDP sockets and they think in a naive way that they work like
this:

\begin{description}
\item [TCP] Programmers think these are streamed sequential messages, so if
   they send a "message" that's 10k long then when the receiver gets it and read
   from the TCP socket they get a single 10k message in reply.  This only works in
   small messages and not on the internet, so it's easy to see how it would seem
   to work that way.  The reality is you can get messages of any size, and without
   some framing mechanism you wouldn't know where one messages ends or beings.
   TCP is a \emph{streaming protocol}.

\item [UDP] Programmers think UDP sockets are single fast \emph{reliable} messages
    that can be sent to one or more target clients.  They at least know UDP has a fixed
    upper bound size, but they don't get that UDP is very unreliable and that the addressing
    is fairly weak.
\end{description}

What ZeroMQ does is create an API that looks a lot like sockets, and feels the
same, but gives you the messaging styles you actually want.  By simply
specifying the type of socket when you call
\href{http://api.zeromq.org/zmq\_socket.html}{zmq\_socket} you can have
multicast, request/reply, and many other styles.  Here's the list of ones
currently implemented (as documented in \shell{man zmq\_socket}):

\begin{description}
\item [ZMQ\_REQ ZMQ\_REP]  Your classic strict REQuest/REPly sockets, that work much like 
    HTTP request/response semantics.  These are more strict and lock-step, but are slower
    because of the extra overhead in keeping the state organized.
\item [ZMQ\_PUB ZMQ\_SUB]  These are PUBlish/SUBscribe sockets and work as a decentralized 
    asynchronous messaging.  PUB sockets just send out messages to multiple subscribers, without
    expecting a reply.  SUB sockets just read messages that are sent to them, and can subscribe
    to prefixes on the messages.
\item [ZMQ\_DOWNSTREAM ZMQ\_UPSTREAM] DOWN/UP sockets are more like asynchronous round-robin 
    sockets.  They work like PUB/SUB, but instead of the message going to all subscribers that
    are subscribed or not, a DOWN/UP socket will have a message go to just one of the receivers
    in a cluster.  This is a lot like having a round-robin proxy configuration in your web server.
\item [ZMQ\_PAIR] A PAIR is just a direct connection between two peers, basically like a better
    TCP connection.
\end{description}

The next thing ZeroMQ does is it separates these types of \emph{messaging} from the underlying 
transport protocol and gives you a simple URL-like syntax for specifying that: \shell{tcp://127.0.0.1:9999/}
for example.  The types of transports that you can use when you call \href{http://api.zeromq.org/zmq\_bind.html}{zmq\_bind}
and \href{http://api.zeromq.org/zmq\_connect.html}{zmq\_connect} are:

\begin{description}
\item [tcp://] This is a plain old TCP socket with a host and portnumber.
\item [ipc://] This uses Unix inter-process communication like domain sockets, mq, or whatever is available.
\item [pgm://] Reliable multicast messaging that uses raw IP layering and requires special privileges.
\item [epgm://] The "encapsulated" version that uses regular UDP to do reliable multicast messaging.
\end{description}

Finally, ZeroMQ then divorces who binds and connects from the above two
configurations.  This means that unlike classic sockets who connects and who
binds doesn't matter for the direction or kind of message.  All that really
matters is whether the connection makes sense for your application.  For
example, in Mongrel2 the server does a bind on the handler ports so that
handlers can connect at will, which gives your handlers a nice "zero config"
setup.  Mongrel2 doesn't need to know about handlers, they just need to know
about Mongrel2.

How this last part works, and why it works, is that when clients or servers
connect or disconnect, ZeroMQ \emph{doesn't blow up}.  In TCP, if I have a
server, and then 10 clients connect, when one of them disconnects in the middle
of a message I lose the message and get an error.  With ZeroMQ, clients
connecting to a socket don't trigger an event, and disconnecting doesn't do
anything other than hold or drop messages.  This is why you don't have to care
about who binds or connects, because it's just an addressing mechanism, not a
\emph{state management} mechanism.

Another way to put this feature is there's no \emph{accept} in ZeroMQ.  Clients
connect and go at will and the server is just reading messages off when they're
available or sending them out for clients.


\subsection{A Quick Python ZeroMQ Example}

I've written a simple abstraction over ZeroMQ that fits the Mongrel2 usage of it, but
I think learning how you'd write your own ZeroMQ simple echo server in Python will
help you get a handle on it.  First the client then the server:

\begin{code}{Simple Python ZeroMQ Client}
\begin{Verbatim}
import zmq

ctx = zmq.Context()
s = ctx.socket(zmq.SUB)
s.connect("tcp://127.0.0.1:5566")
s.setsockopt(zmq.SUBSCRIBE, '')

msg = s.recv()
print "MSG: ", repr(msg)
\end{Verbatim}
\end{code}


\begin{code}{Simple Python ZeroMQ Server}
\begin{Verbatim}
import zmq
import time

ctx = zmq.Context()
s = ctx.socket(zmq.PUB)
s.bind("tcp://127.0.0.1:5566")

while True:
    s.send("HELLO")
    time.sleep(1)
\end{Verbatim}
\end{code}


You can then run these two in different windows and they will talk to each
other.  Try playing around with different socket types and transports to see
what they do.  Notice that for a PUB/SUB setup we have to use \ident{setsockopt}
to subscribe the nothing ('').  This is the same no matter what language you
use.

Here's an example that does the sme thing but with REQ/REP style of messages.

\begin{code}{ZeroMQ REQ/REP Client}
\begin{Verbatim}
import zmq

ctx = zmq.Context()
s = ctx.socket(zmq.REQ)
s.connect("tcp://127.0.0.1:5566")

s.send('HI FROM CLIENT')

msg = s.recv()
print "MSG: ", repr(msg)
\end{Verbatim}
\end{code}


\begin{code}{ZeroMQ REQ/REP Server}
\begin{Verbatim}
import zmq

ctx = zmq.Context()
s = ctx.socket(zmq.REP)
s.bind("tcp://127.0.0.1:5566")

while True:
    print "GOT BACK", repr(s.recv())
    s.send("HELLO")
\end{Verbatim}
\end{code}

As you can see when you run this it's more like your classic web server style of messaging
where a client requests something with an initial message, and the server replies.  Try getting
the order wrong and see how ZeroMQ aborts and tells you it's wrong.  REQ sockets \emph{must} send
first then recv, and REP sockets \emph{must} recv then send.

\begin{aside}{There's Always A Size In ZeroMQ Land}
The lack of a reliable framing mechanism in TCP was a crime against humanity.  What I mean by a
"frame" is a simple indicator that a message in a stream has a certain length.  If you preface
each message in TCP with the length of the data you're about to send then you avoid all manner
of annoyance, attacks, and bugs.  Something as simple as a single byte that says you're sending up
to 128 more bytes, with an extra bit to indicate the last byte would have saved the world much
pain.

This is basically what ZeroMQ has done, and so much more.  ZeroMQ pulls out all the tricks to make
sure that the message you receive is totally cooked, fully sized, and transports it faster than
TCP can actually send it.  It does this by framing things intelligently, using compression, reducing
copying, and just generally being awesome.

Of course, the only limitation is that it can't really \emph{stream} things, but then again nobody
really does true streaming.  They always end up having to bolt on some framing of some kind.
\end{aside}


\section{Handlers And Formats}


\section{Python Handler API}


\section{Basic Handler Demo}


\section{Chat Demo}


\section{MP3 Streaming Demo}


\section{Other Language APIs}


\subsection{Ruby Handler API}


\subsection{C++ Handler API}


\subsection{PHP Handler API}


\subsection{Writing Your Own}


\section{Config Database Schema}


\subsection{Writing Your Own m2sh}



